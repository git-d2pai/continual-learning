<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI/ML ë…¼ë¬¸ ì»¬ë ‰ì…˜</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        
        .header {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            padding: 30px;
            margin-bottom: 30px;
            text-align: center;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
        }
        
        .header h1 {
            color: #2d3748;
            font-size: 2.5rem;
            margin-bottom: 10px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        
        .header p {
            color: #666;
            font-size: 1.1rem;
        }
        
        .stats {
            display: flex;
            justify-content: center;
            gap: 30px;
            margin-top: 20px;
        }
        
        .stat {
            text-align: center;
        }
        
        .stat-number {
            font-size: 2rem;
            font-weight: bold;
            color: #667eea;
        }
        
        .stat-label {
            color: #666;
            font-size: 0.9rem;
        }
        
        .search-box {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
        }
        
        .search-input {
            width: 100%;
            padding: 15px;
            border: 2px solid #e2e8f0;
            border-radius: 10px;
            font-size: 16px;
            transition: border-color 0.3s ease;
        }
        
        .search-input:focus {
            outline: none;
            border-color: #667eea;
            box-shadow: 0 0 0 3px rgba(102, 126, 234, 0.1);
        }
        
        .papers {
            display: grid;
            gap: 20px;
        }
        
        .paper {
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }
        
        .paper:hover {
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.15);
        }
        
        .paper-title {
            font-size: 1.3rem;
            font-weight: bold;
            color: #2d3748;
            margin-bottom: 10px;
            line-height: 1.4;
        }
        
        .paper-title a {
            color: inherit;
            text-decoration: none;
            transition: color 0.3s ease;
        }
        
        .paper-title a:hover {
            color: #667eea;
        }
        
        .paper-authors {
            color: #666;
            margin-bottom: 10px;
            font-weight: 500;
        }
        
        .paper-date {
            color: #888;
            font-size: 0.9rem;
            margin-bottom: 15px;
        }
        
        .paper-summary {
            color: #555;
            line-height: 1.6;
            margin-bottom: 15px;
        }
        
        .paper-link {
            display: inline-block;
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            padding: 8px 16px;
            border-radius: 20px;
            text-decoration: none;
            font-size: 0.9rem;
            font-weight: 500;
            transition: transform 0.2s ease;
        }
        
        .paper-link:hover {
            transform: translateY(-2px);
        }
        
        .footer {
            text-align: center;
            margin-top: 50px;
            padding: 20px;
            color: rgba(255, 255, 255, 0.8);
        }
        
        @media (max-width: 768px) {
            .container {
                padding: 10px;
            }
            
            .header h1 {
                font-size: 2rem;
            }
            
            .stats {
                flex-direction: column;
                align-items: center;
                gap: 15px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ§  AI/ML ë…¼ë¬¸ ì»¬ë ‰ì…˜</h1>
            <p>ìµœì‹  ì¸ê³µì§€ëŠ¥ ë° ë¨¸ì‹ ëŸ¬ë‹ ì—°êµ¬ ë…¼ë¬¸ë“¤ì„ í•œ ê³³ì—ì„œ</p>
            
            <div class="stats">
                <div class="stat">
                    <div class="stat-number">10</div>
                    <div class="stat-label">ì´ ë…¼ë¬¸ ìˆ˜</div>
                </div>
                <div class="stat">
                    <div class="stat-number">2025. 7. 24.</div>
                    <div class="stat-label">ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸</div>
                </div>
            </div>
        </div>
        
        <div class="search-box">
            <input type="text" class="search-input" id="searchInput" 
                   placeholder="ë…¼ë¬¸ ì œëª©, ì €ì, í‚¤ì›Œë“œë¡œ ê²€ìƒ‰...">
        </div>
        
        <div class="papers" id="papersContainer">
            
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17748v1" target="_blank">Large Learning Rates Simultaneously Achieve Robustness to Spurious Correlations and Compressibility</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Melih Barsbey, Lucas Prieto, Stefanos Zafeiriou, Tolga Birdal</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">Robustness and resource-efficiency are two highly desirable properties for modern machine learning models. However, achieving them jointly remains a challenge. In this paper, we position high learning rates as a facilitator for simultaneously achieving robustness to spurious correlations and network...</div>
        <a href="http://arxiv.org/abs/2507.17748v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17746v1" target="_blank">Rubrics as Rewards: Reinforcement Learning Beyond Verifiable Domains</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Anisha Gunjal, Anthony Wang, Elaine Lau, Vaskar Nath, Bing Liu, Sean Hendryx</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">Extending Reinforcement Learning with Verifiable Rewards (RLVR) to real-world tasks often requires balancing objective and subjective evaluation criteria. However, many such tasks lack a single, unambiguous ground truth-making it difficult to define reliable reward signals for post-training language...</div>
        <a href="http://arxiv.org/abs/2507.17746v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17745v1" target="_blank">Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Yiwen Chen, Zhihao Li, Yikai Wang, Hu Zhang, Qin Li, Chi Zhang, Guosheng Lin</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">Recent advances in sparse voxel representations have significantly improved the quality of 3D content generation, enabling high-resolution modeling with fine-grained geometry. However, existing frameworks suffer from severe computational inefficiencies due to the quadratic complexity of attention me...</div>
        <a href="http://arxiv.org/abs/2507.17745v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17743v1" target="_blank">Educational Insights from Code: Mapping Learning Challenges in Object-Oriented Programming through Code-Based Evidence</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Andre Menolli, Bruno Strik</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">Object-Oriented programming is frequently challenging for undergraduate Computer Science students, particularly in understanding abstract concepts such as encapsulation, inheritance, and polymorphism. Although the literature outlines various methods to identify potential design and coding issues in ...</div>
        <a href="http://arxiv.org/abs/2507.17743v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17740v1" target="_blank">Quantum stroboscopy for time measurements</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Seth Lloyd, Lorenzo Maccone, Lionel Martellini, Simone Roncallo</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">Mielnik's cannonball argument uses the Zeno effect to argue that projective measurements for time of arrival are impossible. If one repeatedly measures the position of a particle (or a cannonball!) that has yet to arrive at a detector, the Zeno effect will repeatedly collapse its wavefunction away f...</div>
        <a href="http://arxiv.org/abs/2507.17740v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17731v1" target="_blank">Flow Matching Meets Biology and Life Science: A Survey</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Zihao Li, Zhichen Zeng, Xiao Lin, Feihao Fang, Yanru Qu, Zhe Xu, Zhining Liu, Xuying Ning, Tianxin Wei, Ge Liu, Hanghang Tong, Jingrui He</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">Over the past decade, advances in generative modeling, such as generative adversarial networks, masked autoencoders, and diffusion models, have significantly transformed biological research and discovery, enabling breakthroughs in molecule design, protein generation, drug discovery, and beyond. At t...</div>
        <a href="http://arxiv.org/abs/2507.17731v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17728v1" target="_blank">Megrez2 Technical Report</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Boxun Li, Yadong Li, Zhiyuan Li, Congyi Liu, Weilin Liu, Guowei Niu, Zheyue Tan, Haiyang Xu, Zhuyu Yao, Tao Yuan, Dong Zhou, Yueqing Zhuang, Bo Zhao, Guohao Dai, Yu Wang</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">We present Megrez2, a novel lightweight and high-performance language model architecture optimized for device native deployment. Megrez2 introduces a novel cross-layer expert sharing mechanism, which significantly reduces total parameter count by reusing expert modules across adjacent transformer la...</div>
        <a href="http://arxiv.org/abs/2507.17728v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17727v1" target="_blank">CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Robel Mamo, Taeyeong Choi</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">State-of-the-art visual under-canopy navigation methods are designed with deep learning-based perception models to distinguish traversable space from crop rows. While these models have demonstrated successful performance, they require large amounts of training data to ensure reliability in real-worl...</div>
        <a href="http://arxiv.org/abs/2507.17727v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17726v1" target="_blank">Deep Generative Learning of Magnetic Frustration in Artificial Spin Ice from Magnetic Force Microscopy Images</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Arnab Neogi, Suryakant Mishra, Prasad P Iyer, Tzu-Ming Lu, Ezra Bussmann, Sergei Tretiak, Andrew Crandall Jones, Jian-Xin Zhu</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">Increasingly large datasets of microscopic images with atomic resolution facilitate the development of machine learning methods to identify and analyze subtle physical phenomena embedded within the images. In this work, microscopic images of honeycomb lattice spin-ice samples serve as datasets from ...</div>
        <a href="http://arxiv.org/abs/2507.17726v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
    <div class="paper">
        <h2 class="paper-title">
            <a href="http://arxiv.org/abs/2507.17725v1" target="_blank">On the Interaction of Compressibility and Adversarial Robustness</a>
        </h2>
        <div class="paper-authors">ğŸ‘¥ Melih Barsbey, AntÃ´nio H. Ribeiro, Umut ÅimÅŸekli, Tolga Birdal</div>
        <div class="paper-date">ğŸ“… 2025. 7. 23.</div>
        <div class="paper-summary">Modern neural networks are expected to simultaneously satisfy a host of desirable properties: accurate fitting to training data, generalization to unseen inputs, parameter and computational efficiency, and robustness to adversarial perturbations. While compressibility and robustness have each been s...</div>
        <a href="http://arxiv.org/abs/2507.17725v1" target="_blank" class="paper-link">
            ğŸ“„ ë…¼ë¬¸ ë³´ê¸°
        </a>
    </div>
  
        </div>
        
        <div class="footer">
            <p>ğŸ“Š ë°ì´í„° ì¶œì²˜: ArXiv | ğŸ”„ ìë™ ì—…ë°ì´íŠ¸: n8n</p>
        </div>
    </div>
    
    <script>
        // ì‹¤ì‹œê°„ ê²€ìƒ‰ ê¸°ëŠ¥
        const searchInput = document.getElementById('searchInput');
        const papersContainer = document.getElementById('papersContainer');
        const allPapers = Array.from(document.querySelectorAll('.paper'));
        
        searchInput.addEventListener('input', function() {
            const searchTerm = this.value.toLowerCase();
            
            allPapers.forEach(paper => {
                const title = paper.querySelector('.paper-title').textContent.toLowerCase();
                const authors = paper.querySelector('.paper-authors').textContent.toLowerCase();
                const summary = paper.querySelector('.paper-summary').textContent.toLowerCase();
                
                const isMatch = title.includes(searchTerm) || 
                              authors.includes(searchTerm) || 
                              summary.includes(searchTerm);
                
                paper.style.display = isMatch ? 'block' : 'none';
            });
        });
        
        // ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼
        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        });
        
        allPapers.forEach(paper => {
            paper.style.opacity = '0';
            paper.style.transform = 'translateY(20px)';
            paper.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
            observer.observe(paper);
        });
    </script>
</body>
</html>